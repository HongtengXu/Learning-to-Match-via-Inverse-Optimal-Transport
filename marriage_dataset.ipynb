{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sklearn.cluster\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "import ot\n",
    "from functools import reduce\n",
    "from Matcher import Matcher, train_parameters, model_parameters\n",
    "from sklearn.model_selection import KFold\n",
    "from utils import computeMAE, computeRMSE\n",
    "from scipy import sparse\n",
    "from fastFM import als\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD, SVDpp, NMF, KNNWithMeans, KNNBasic, KNNWithZScore, NormalPredictor, SlopeOne, accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(year):\n",
    "    # clean hhi dataset\n",
    "    hhi = pd.read_csv(\"DHS data/csv/hhi\" + str(year) + \".csv\")\n",
    "    hhi = hhi[['nohhold', 'nomem', 'geslacht', 'positie', 'oplmet']]\n",
    "    hhi.columns = ['household_index', 'member_index', 'gender', 'relationship', 'education']\n",
    "    hhi['gender'] = hhi['gender'].apply(lambda x: 'M' if x == 1 else 'F')\n",
    "    hhi = hhi[(hhi['relationship'] == 1) | (hhi['relationship'] == 2)]\n",
    "    hhi = hhi[hhi['education'] != 9]\n",
    "    def transformEducation(x):\n",
    "        if x in {'6', '7'}:\n",
    "            return 'High'\n",
    "        if x in {'3', '4', '5'}:\n",
    "            return 'Middle'\n",
    "        if x in {'1', '2'}:\n",
    "            return 'Low'\n",
    "        if x == '8':\n",
    "            return 'Uneducated'\n",
    "    hhi['education'] = hhi['education'].apply(transformEducation)\n",
    "    hhi = hhi.groupby('household_index').filter(lambda x: len(x) > 1)\n",
    "    hhi['index'] = 100 * hhi['household_index'] + hhi['member_index']\n",
    "    hhi = hhi.set_index('index')\n",
    "    hhi.dropna(inplace=True)\n",
    "    \n",
    "    # clean inc dataset\n",
    "    inc = pd.read_csv(\"DHS data/csv/inc\" + str(year) + \".csv\")\n",
    "    inc = inc[['nohhold', 'nomem', 'gez1', 'gez2', 'gez3']]\n",
    "    inc.columns = ['household_index', 'member_index', 'height', 'weight', 'health']\n",
    "    inc['index'] = 100 * inc['household_index'] + inc['member_index']\n",
    "    inc = inc.set_index('index')\n",
    "    inc.dropna(inplace=True)\n",
    "\n",
    "    # clean psy dataset\n",
    "    psy = pd.read_csv(\"DHS data/csv/psy\" + str(year) + \".csv\")\n",
    "    psy = psy[['nohhold', 'nomem', \n",
    "               'con04', 'con06', 'con08',\n",
    "               'con03', 'con10', 'con09',\n",
    "               'con05'\n",
    "               ]]\n",
    "    psy.columns = ['household_index', 'member_index',\n",
    "                   'irresponsible', 'accurate', 'ever-ready',\n",
    "                   'disciplined', 'ordered', 'clumsy',\n",
    "                   'detail-oriented']\n",
    "    for feature in ['irresponsible', 'accurate', 'ever-ready',\n",
    "                   'disciplined', 'ordered', 'clumsy',\n",
    "                   'detail-oriented']:\n",
    "        psy[feature] = pd.to_numeric(psy[feature], errors='coerce')\n",
    "    psy['index'] = 100 * psy['household_index'] + psy['member_index']\n",
    "    psy = psy.set_index('index')\n",
    "    psy.dropna(inplace=True)\n",
    "    \n",
    "    # join three datasets and remove duplicate columns\n",
    "    df = hhi.join(inc, rsuffix='_inc').join(psy, rsuffix='_psy')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.groupby('household_index').filter(lambda x: len(x) == 2)\n",
    "    del df['household_index_inc'], df['household_index_psy'], df['member_index_inc'], df['member_index_psy']\n",
    "    df.reset_index(inplace=True)\n",
    "    del df['index']\n",
    "    household_index = reduce(lambda x, y: x + y, [[i, i] for i in range((year - 2005)*1000, (year - 2005)*1000 + len(df) // 2)])\n",
    "    df['household_index'] = household_index\n",
    "    \n",
    "    df.to_csv('DHS data/cleaned/' + str(year) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean all datasets (excluding 2008)\n",
    "for year in range(2005, 2015):\n",
    "    if year == 2008:\n",
    "        continue\n",
    "    preProcessing(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataset of different years into one\n",
    "dfs = []\n",
    "for year in range(2005, 2015):\n",
    "    if year == 2008:\n",
    "        continue\n",
    "    df = pd.read_csv('DHS data/cleaned/' + str(year) + '.csv')\n",
    "    del df['Unnamed: 0']\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df = df[(df['height'] > 100) & (df['height'] < 200)]\n",
    "df = df[df['weight'] > 10]\n",
    "df.to_csv('DHS data/cleaned/cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DHS data/cleaned/cleaned.csv')\n",
    "df = df.groupby('household_index').filter(lambda x: len(x)>1)\n",
    "del df['Unnamed: 0']\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normailizeEducation(edu):\n",
    "    if edu == 'High':\n",
    "        return 1.0\n",
    "    if edu == 'Middle':\n",
    "        return 2.0 / 3\n",
    "    if edu == 'Low':\n",
    "        return 1.0 / 3\n",
    "    if edu == 'Uneducated':\n",
    "        return 0.0\n",
    "df['education'] = df['education'].apply(normailizeEducation)\n",
    "df['height'] = df['height'] / df['height'].max()\n",
    "df['weight'] = df['weight'] /df['weight'].max()\n",
    "df['health'] = (6.0 - df['health']) / 5.0\n",
    "\n",
    "for feature in ['irresponsible', 'accurate', 'ever-ready',\n",
    "                   'disciplined', 'ordered', 'clumsy',\n",
    "                   'detail-oriented']:\n",
    "    df[feature] = df[feature] / 5.0\n",
    "\n",
    "df = df.groupby('household_index').filter(lambda group: len(group) == 2)\n",
    "df = df.groupby('household_index').filter(lambda group: len(group[group.gender == 'M']) == 1)\n",
    "df.to_csv('DHS data/normalized/normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(n_clusters):\n",
    "    df['label'] = np.nan\n",
    "    M = df[df['gender'] == 'M']\n",
    "    F = df[df['gender'] == 'F']\n",
    "    cluster_M = sklearn.cluster.KMeans(n_clusters)\n",
    "    cluster_F = sklearn.cluster.KMeans(n_clusters)\n",
    "    cluster_M.fit(M[['education', 'height', 'weight', 'health', 'irresponsible', 'accurate', 'ever-ready', 'disciplined', 'ordered', 'clumsy', 'detail-oriented']])\n",
    "    cluster_F.fit(F[['education', 'height', 'weight', 'health', 'irresponsible', 'accurate', 'ever-ready', 'disciplined', 'ordered', 'clumsy', 'detail-oriented']])\n",
    "    df.loc[df.gender == 'M', 'label'] = cluster_M.labels_\n",
    "    df.loc[df.gender == 'F', 'label'] = cluster_F.labels_\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    U0 = cluster_M.cluster_centers_.T\n",
    "    V0 = cluster_F.cluster_centers_.T\n",
    "    return U0, V0\n",
    "\n",
    "n_clusters = 50\n",
    "U0, V0 = cluster(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(len(df) // 2):\n",
    "    if df.iloc[2*i]['gender'] == 'M' and df.iloc[2*i+1]['gender'] == 'F':\n",
    "        dataset.append(list(df.iloc[2*i][4:]) + list(df.iloc[2*i+1][4:]))\n",
    "    else:\n",
    "        dataset.append(list(df.iloc[2*i+1][4:]) + list(df.iloc[2*i][4:]))\n",
    "dataset = np.asarray(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset, n_clusters):\n",
    "    m = n_clusters\n",
    "    pi_sample = np.zeros((m, m))\n",
    "\n",
    "    for k in range(len(dataset)):\n",
    "        i = int(dataset[k][11])\n",
    "        j = int(dataset[k][23])\n",
    "        pi_sample[i][j] += 1\n",
    "\n",
    "    pi_sample /= len(dataset)\n",
    "    \n",
    "    rating = []\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            rating.append([i, j, pi_sample[i][j]])\n",
    "        \n",
    "    X, Y = [], []\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            X.append(np.append(U0[:,i].reshape(11), V0[:,j].reshape(11)))\n",
    "            Y.append(pi_sample[i][j])\n",
    "        \n",
    "    return pi_sample, rating, sparse.csr_matrix(np.asarray(X)), np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model   | RMSE   |  MAE\n",
      " Random  | 0.00540 |  0.00362\n",
      " PMF     | 0.00715 |  0.00335\n",
      " SVD     | 0.01105 |  0.00626\n",
      " itemKNN | 0.00024 |  0.00016\n",
      " RiOT    | 0.00023 |  0.00015\n",
      " FM      | 0.00095 |  0.00076\n"
     ]
    }
   ],
   "source": [
    "n_fold = 5\n",
    "kf = KFold(n_fold, random_state=3)\n",
    "\n",
    "metric_Random = np.zeros(2)\n",
    "metric_PMF = np.zeros(2)\n",
    "metric_SVD = np.zeros(2)\n",
    "metric_itemKNN = np.zeros(2)\n",
    "metric_RiOT = np.zeros(2)\n",
    "metric_FM = np.zeros(2)\n",
    "\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(dataset)):\n",
    "    train_dataset, test_dataset = dataset[train_index], dataset[test_index] \n",
    "    train_pi_sample, train_rating, train_X, train_Y = get_data(train_dataset, n_clusters)\n",
    "    test_pi_sample, test_rating, test_X, test_Y = get_data(test_dataset, n_clusters)\n",
    "    \n",
    "    labels = ['user', 'item', 'rating']\n",
    "    reader = Reader(rating_scale=(0, 2))\n",
    "    df = pd.DataFrame.from_records(train_rating, columns=labels)\n",
    "    train_surprise = Dataset.load_from_df(df[['user', 'item', 'rating']], reader).build_full_trainset()\n",
    "    df = pd.DataFrame.from_records(test_rating, columns=labels)\n",
    "    test_surprise = Dataset.load_from_df(df[['user', 'item', 'rating']], reader).build_full_trainset().build_testset()\n",
    "\n",
    "    # Random\n",
    "    algo = NormalPredictor()\n",
    "    algo.fit(train_surprise)\n",
    "    predictions = algo.test(test_surprise)\n",
    "\n",
    "    metric_Random[0] += accuracy.rmse(predictions, verbose=False)\n",
    "    metric_Random[1] += accuracy.mae(predictions, verbose=False)\n",
    "\n",
    "    # PMF\n",
    "    algo = SVD(biased=False)\n",
    "    algo.fit(train_surprise)\n",
    "    predictions = algo.test(test_surprise)\n",
    "\n",
    "    metric_PMF[0] += accuracy.rmse(predictions, verbose=False)\n",
    "    metric_PMF[1] += accuracy.mae(predictions, verbose=False)\n",
    "\n",
    "    # SVD\n",
    "    algo = SVD()\n",
    "    algo.fit(train_surprise)\n",
    "    predictions = algo.test(test_surprise)\n",
    "\n",
    "    metric_SVD[0] += accuracy.rmse(predictions, verbose=False)\n",
    "    metric_SVD[1] += accuracy.mae(predictions, verbose=False)\n",
    "    \n",
    "    # ItemKNN\n",
    "    algo = KNNWithMeans(k=50, sim_options = {'user_based': False}, verbose=False)\n",
    "    algo.fit(train_surprise)\n",
    "    predictions = algo.test(test_surprise)\n",
    "\n",
    "    metric_itemKNN[0] += accuracy.rmse(predictions, verbose=False)\n",
    "    metric_itemKNN[1] += accuracy.mae(predictions, verbose=False)   \n",
    "\n",
    "    # RiOT\n",
    "    model = Matcher(train_pi_sample, U0, V0, r=5)\n",
    "    lam = 1\n",
    "    model_param = model_parameters(A0=np.eye(11, 11),\n",
    "                                          gamma=0.2,\n",
    "                                          const=1,\n",
    "                                          degree=2,\n",
    "                                          lam=lam,\n",
    "                                          lambda_mu=1,\n",
    "                                          lambda_nu=1,\n",
    "                                          delta=0.005)\n",
    "    train_param = train_parameters(max_outer_iteration=20,\n",
    "                                          max_inner_iteration=10,\n",
    "                                          learning_rate=0.01)\n",
    "    model.riot(model_param, train_param)\n",
    "    test_r, test_c = test_pi_sample.sum(axis=1), test_pi_sample.sum(axis=0)\n",
    "    pred_pi = ot.rot(model.C, test_r, test_c, lam)[0]\n",
    "    error_OT = (pred_pi - test_pi_sample).reshape(1, n_clusters*n_clusters)\n",
    "    metric_RiOT += np.array([computeRMSE(error_OT), computeMAE(error_OT)])\n",
    "    \n",
    "    # factorization machine\n",
    "    fm = als.FMRegression(n_iter=1000, init_stdev=0.1, rank=15, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "    fm.fit(train_X,train_Y)\n",
    "    pred_Y = fm.predict(test_X)\n",
    "    error_FM = pred_Y - test_Y\n",
    "    metric_FM += np.array([computeRMSE(error_FM), computeMAE(error_FM)])\n",
    "    \n",
    "    metric_PMF /= n_fold\n",
    "    metric_SVD /= n_fold\n",
    "    metric_itemKNN /= n_fold\n",
    "    metric_RiOT /= n_fold\n",
    "    metric_FM /= n_fold\n",
    "        \n",
    "print(' model   | RMSE   |  MAE')\n",
    "print(' Random  | {:.5f} |  {:.5f}'.format(metric_Random[0], metric_Random[1]))\n",
    "print(' PMF     | {:.5f} |  {:.5f}'.format(metric_PMF[0], metric_PMF[1]))\n",
    "print(' SVD     | {:.5f} |  {:.5f}'.format(metric_SVD[0], metric_SVD[1]))\n",
    "print(' itemKNN | {:.5f} |  {:.5f}'.format(metric_itemKNN[0], metric_itemKNN[1]))\n",
    "print(' RiOT    | {:.5f} |  {:.5f}'.format(metric_RiOT[0], metric_RiOT[1]))\n",
    "print(' FM      | {:.5f} |  {:.5f}'.format(metric_FM[0], metric_FM[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
